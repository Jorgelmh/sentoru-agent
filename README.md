<table>
  <tr>
    <td><img src="docs/resources/sentoru-logo.png" alt="Sentoru Logo" width="100"></td>
    <td><h1>üîêü•∑ Sentoru Agent ‚Äì Secure Coding for the AI Era</h1></td>
  </tr>
</table>

**Sentoru** is an AI **secure coding** agent designed to enforce cybersecurity best practices across your pull requests (PRs). By leveraging specialized agents, Sentoru automatically analyzes, fixes, and pen‚Äëtests your code to ensure that every PR meets enterprise‚Äëgrade security standards.

## üöÄ Key Features

- **Cybersecurity‚Äëfirst PR workflows** ‚Äì Automatically scans PRs for vulnerabilities and injects secure coding checks directly into your GitHub CI/CD pipeline.
- **AI‚Äëaugmented security** ‚Äì In an era where vibe coding is accelerating development, rapidly generated AI code often skips deep security scrutiny. Sentoru fills this gap by **automatically verifying, hardenning, and pen-testing** AI-generated code‚Äîensuring that fast innovation doesn't come at the cost of vulnerabilities.
- **Instant feedback** ‚Äì Posts comments, suggestions, and status checks directly in your PRs for seamless review.
- **Developer control & flexibility** ‚Äì Sentoru doesn't force changes. You choose when its security suggestions, fixes, or attack tests are relevant‚Äîopting in or out on a per-PR or per-repository basis. Whether it's an urgent hotfix or a risk-free proof-of-concept, you stay in command of what gets hardened and what doesn't.

## Architecture

![Architecture Diagram](docs/resources/architecture-diagram.png)

## üõ°Ô∏è Why It Matters

1. **Vibe coding**‚Äîcoding by prompting AI‚Äîis gaining traction. While it's fast and intuitive, it also introduces frequent security vulnerabilities.
2. Research shows **30%‚Äì50% of AI‚Äëgenerated code** contains security flaws like SQL injection, XSS, and authentication weaknesses.
3. Sentoru closes the secure‚Äëcoding feedback loop: code generated by AI is immediately analyzed, fixed, and validated‚Äîso you can merge with confidence.

## How It Works: A Multi-Agent System

Sentoru operates as a sequence of specialized AI agents, each with a distinct role in the security workflow. This multi-agent system ensures a thorough and structured approach to securing your code.

The process is orchestrated by a `SequentialAgent` that runs the following agents in order:

1.  **Analyst Agent**:
    *   **Responsibility**: This is the first agent in the chain. It analyzes the code changes in a pull request to identify potential security vulnerabilities.
    *   **Tools**:
        *   `get_safety_API_tool`: Checks for known vulnerabilities in `requirements.txt` or `pyproject.toml` using the [Safety CLI](https://www.getsafety.com/cli) vulnerability database.
        *   `get_rag_vulnerability_knowledge_tool`: Consults a knowledge base of cybersecurity guidelines and best practices using Retrieval-Augmented Generation (RAG) on Vertex AI to provide context on relevant vulnerabilities for the new code changes.
    *   **Output**: A detailed analysis report of its findings.

2.  **Fixer Agent**:
    *   **Responsibility**: This agent takes the `Analyst Agent`'s report and generates code patches to fix the identified vulnerabilities.
    *   **Method**: It follows a detailed prompt that instructs it to create suggestions in the GitHub-approved patch format, including comments that explain the vulnerability and the fix.
    *   **Output**: A JSON object containing an array of code patches and a summary comment.

3.  **Pentester Agent**:
    *   **Responsibility**: The final agent in the sequence. It validates that the patches from the `Fixer Agent` are secure and don't introduce new flaws.
    *   **Method**: It adopts an adversarial mindset to write `pytest` unit tests that act as penetration tests, simulating the original attack vector to ensure the fix is robust.
    *   **Output**: A new test file containing the penetration tests, along with an explanation of the tests.

This sequential process ensures that every pull request is analyzed, fixed, and validated before it gets merged.

---

**Build faster. Secure smarter. Embrace AI with confidence.**

---

## ‚úÖ Quick Start

### Installation

Before you begin, ensure you have the following prerequisites installed:
- **uv**: Python package manager - [Install](https://docs.astral.sh/uv/getting-started/installation/)
- **Google Cloud SDK**: For GCP services - [Install](https://cloud.google.com/sdk/docs/install)

1.  **Sync Python dependencies**

    Install the required Python packages using `uv`:

    ```bash
    uv sync
    ```

2.  **Create a Safety Account**

    Create an account on [Safety](https://www.getsafety.com/cli) and get your API key. You will need this for vulnerability scanning.

3.  **Set up environment variables**

    Create a `.env` file in the root of the project and add the following environment variables:

    ```env
    GOOGLE_CLOUD_PROJECT=<your-gcp-project-id>
    GOOGLE_GENAI_USE_VERTEXAI=True
    GOOGLE_CLOUD_LOCATION=us-central1
    LLM_DEPLOYMENT=gemini-2.0-flash
    SAFETY_API_KEY=<your-safety-mcp-apikey>
    ```

### Running the Agent

To run the agent locally for development and testing, the best way to try it out is by using the `notebooks/adk_app_testing.ipynb` notebook. Where you can either run the Agent flow locally or connect to the cloud resource running in Google Cloud's Vertex AI. In the notebook, you can experiment by providing different git diff files and inspect the JSON responses from the agent to see the security analysis, code fixes, and generated penetration tests.

> **Note**: A generic web interface is available by running `uv run adk web`, but it is not suitable for this agent. This agent requires specific session state, including a git diff, to be passed in, which is best handled through the testing notebook.


